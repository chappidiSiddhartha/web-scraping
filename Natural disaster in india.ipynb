{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 months ago \n",
      "Disasters that struck India in 2020\n",
      " India amidst the raging pandemic survived cyclones floods rains biblical plagues and industrial disasters. As we enter the new year here is a...\n",
      "https://timesofindia.indiatimes.com/india/disasters-that-struck-india-in-2020/articleshow/79954339.cms\n",
      "4 months ago \n",
      "300 disasters 80000 deaths 100 crore affected: India’s two-decade tryst with natural calamities\n",
      " Both nations accounted for over 280 crore disaster-affected people ... The flash floods in Kerala in August 2018 took 504 lives and affected 2.3...\n",
      "https://www.indiatoday.in/diu/story/300-disasters-80-000-deaths-100-crore-affected-india-s-two-decade-tryst-with-natural-calamities-1767202-2021-02-08\n",
      "4 months ago \n",
      "A Look At Natural Disasters Uttarakhand Faced Over Last Three Decades\n",
      " Take a look at the major natural disasters Uttarakhand has faced in the ... Malpa landslide was one of the major natural disasters mankind has ... 2013 North India Floods ... Copyright � 2018 Outlook Publishing India Pvt. Ltd.\n",
      "https://www.outlookindia.com/website/story/india-news-a-look-at-natural-disasters-uttarakhand-faced-over-last-three-decades/373581\n",
      "3 months ago \n",
      "Uttarakhand dam disaster: What caused India's deadly flood?\n",
      " ... analysed the cause of the flood that has devastated Uttarakhand in northern India. ... Disasters of this kind are becoming more frequent in the Himalayas with many ... Using satellite imagery scientists have been piecing together what happened. ... This satellite image shows the Tapovan dam in 2018.\n",
      "https://news.sky.com/story/uttarakhand-dam-disaster-what-caused-indias-deadly-flood-12214731\n",
      "4 months ago \n",
      "Global warming and vanishing glaciers: Is rising temperature behind Uttarakhand disaster?\n",
      " The disaster in Uttarakhand has once again turned the spotlight on ... Earth data to track temperature change in Indian and global cities. ... A similar event had happened in the region around 2016 (probably ... India Today Education � Vasant Valley � Best Colleges India 2018 � Best Universities India 2018...\n",
      "https://www.indiatoday.in/diu/story/global-warming-and-vanishing-glaciers-is-rising-temperature-behind-uttarakhand-disaster-1767257-2021-02-09\n",
      "10 months ago\n",
      "News | More than 200 natural disasters across world in 1st half of 2020\n",
      "� Cyclone Amphan was the world's costliest natural disaster at an ... The cyclone had devastated the Gulf of Bengal — India and Bangladesh — in May 2020. ... of the deaths due to tropical cyclones in the first half of 2019 occurred in Africa ... South America witnessed extreme lightning strikes in 2018 2019:...\n",
      "https://www.downtoearth.org.in/news/climate-change/more-than-200-natural-disasters-across-world-in-1st-half-of-2020-72445\n",
      "7 months ago \n",
      "Hyderabad floods highlight the need for a disaster mitigation and ...\n",
      " Extreme rainfall events occurred in Hyderabad in 2016 2010 and 2000. Kerala was swamped by floods in 2018 and Chennai battered in 2015. ... from the Indian Space Research Organisation (ISRO) and conducted a dozen...\n",
      "https://india.mongabay.com/2020/11/hyderabad-floods-highlight-the-need-for-a-disaster-mitigation-and-climate-resilience-plan/\n",
      "17 months ago\n",
      "Top 5: Most Devastating Natural Disasters to Affect India in 2019 ...\n",
      "� The year 2019 has seen almost all parts of India suffer a wide range of natural disasters. From excruciating heat waves to record number of...\n",
      "https://weather.com/en-IN/india/news/news/2019-12-26-top-5-most-devastating-natural-disasters-affect-india-2019\n",
      "10 months ago\n",
      "Natural Disasters 2019 - World\n",
      "� India was hit hardest and recorded nearly 20% of the total deaths and ... decade (2009-2018) in 2019 there were more disasters compared to...\n",
      "https://reliefweb.int/report/world/natural-disasters-2019\n",
      "12 months ago\n",
      "List of 7 major natural disasters in the history of India\n",
      "� 2. Uttarakhand Flash Floods 2013 � 3. Bihar flood disaster 2007 � 4. The Indian Ocean Tsunami 2004 � 5. Gujarat Earthquake2001 � 6. Super...\n",
      "https://www.jagranjosh.com/general-knowledge/list-of-major-natural-disasters-in-the-history-of-india-1590147440-1\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "DataFrame constructor not properly called!",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-1e6ce9f809d6>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     50\u001b[0m   \u001b[1;31m#print(\"new link:\",link)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     51\u001b[0m     \u001b[0mnews\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlink\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 52\u001b[1;33m \u001b[0mnews\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlink\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     53\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     54\u001b[0m \u001b[0mdata1\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-3-1e6ce9f809d6>\u001b[0m in \u001b[0;36mnews\u001b[1;34m(link)\u001b[0m\n\u001b[0;32m     46\u001b[0m     \u001b[0mlink\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mroot\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mnext\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'href'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;31m#\"/search?q=disasters+occured+in+india+from+2018&amp;biw=1536&amp;bih=651&amp;ie=UTF-8&amp;tbm=nws&amp;ei=s67BYJcPxdr0A6PWh4gN&amp;start=10&amp;sa=N\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     47\u001b[0m     \u001b[1;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 48\u001b[1;33m     \u001b[0mnew\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdict\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     49\u001b[0m     \u001b[0mnew\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_excel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'output.xlsx'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     50\u001b[0m   \u001b[1;31m#print(\"new link:\",link)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[0;32m    483\u001b[0m                 )\n\u001b[0;32m    484\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 485\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"DataFrame constructor not properly called!\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    486\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    487\u001b[0m         \u001b[0mNDFrame\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmgr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfastpath\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: DataFrame constructor not properly called!"
     ]
    }
   ],
   "source": [
    "#extracting Links,Descriptions,Titles \n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from urllib.request import Request, urlopen\n",
    "root='https://www.google.com/'\n",
    "link='https://www.google.com/search?q=disasters+occured+in+india+from+2018&biw=1536&bih=651&sxsrf=ALeKk01kD35sPRBzyxzN9mvjDtDdusiycQ:1623156141280&source=lnt&tbs=cdr:1,cd_min:1/1/2018,cd_max:6/6/2021&tbm=nws&safe=images'\n",
    "def news(link):\n",
    "  req = Request(link,headers={'User-Agent':'Chrome'})\n",
    "  webpage = urlopen(req).read()\n",
    "  with requests.Session() as c:\n",
    "\n",
    "    soup=BeautifulSoup(webpage,'html5lib')\n",
    "    #print(soup)\n",
    "    #Citing an example to The Better India, Pradeep says, “On New Year's Eve in \n",
    "#2018, we received a call from a local that there was a puppy stuck inside \n",
    "#the ...\n",
    "    descript=[]\n",
    "    titles=[]\n",
    "    links=[]\n",
    "    times=[]\n",
    "    for item in soup.find_all('div',attrs={'class':'ZINbbc xpd O9g5cc uUPGi'}):\n",
    "\n",
    "#kCrYT\n",
    "      rawlink=(item.find('a',href=True)['href'])\n",
    "      link1=rawlink.split(\"/url?q=\")[1].split('&sa=U&')[0]\n",
    "      title1=(item.find('div',attrs={'class':'BNeawe vvjwJb AP7Wnd'})).get_text()\n",
    "      description=(item.find('div',attrs={'class':'BNeawe s3v9rd AP7Wnd'})).get_text()\n",
    "      title1=title1.replace(\",\",\"\")\n",
    "      description=description.replace(\",\",\"\")\n",
    "      #print(\"title:\",title)\n",
    "\n",
    "      titles.append(title1)\n",
    "      time=(description)[0:13]\n",
    "      print(time)\n",
    "      print(title1)\n",
    "      times.append(time)\n",
    "      descript1=description[14:]\n",
    "      print(descript1)\n",
    "      print(link1)\n",
    "      links.append(link1)\n",
    "\n",
    "      descript.append(descript1)\n",
    "\n",
    "    next = (soup.find('a',attrs={'aria-label':'Next page'}))\n",
    "    #showing type as string,able to print but not add to another string\n",
    "    link=root+next['href']#\"/search?q=disasters+occured+in+india+from+2018&amp;biw=1536&amp;bih=651&amp;ie=UTF-8&amp;tbm=nws&amp;ei=s67BYJcPxdr0A6PWh4gN&amp;start=10&amp;sa=N\"\n",
    "    import pandas as pd\n",
    "    new=pd.DataFrame(dict)\n",
    "    new.to_excel('output.xlsx')\n",
    "  #print(\"new link:\",link)\n",
    "    news(link)\n",
    "news(link)\n",
    "\n",
    "data1=[]\n",
    "titles=[\"Time\",\"Title\",\"Descript\",\"Link\"]\n",
    "data1.append(titles)\n",
    "dict={'Time':times,\"Title\":titles,\"Descript\":descript,\"Link\":links}\n",
    "\n",
    "import pandas as pd\n",
    "new=pd.DataFrame(dict)\n",
    "print(new)\n",
    "new.to_excel('output.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:27: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "C:\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:23: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "C:\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:25: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "C:\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:56: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0           India\n",
      "1           India\n",
      "2           India\n",
      "3           India\n",
      "4     Uttarakhand\n",
      "5       Hyderabad\n",
      "6       Hyderabad\n",
      "7           India\n",
      "8           India\n",
      "9           India\n",
      "10          India\n",
      "11          India\n",
      "12          India\n",
      "13          India\n",
      "14          India\n",
      "15          India\n",
      "16          India\n",
      "17          India\n",
      "18          India\n",
      "19          India\n",
      "Name: location, dtype: object\n",
      "20          India\n",
      "21    Uttarakhand\n",
      "22             US\n",
      "23             US\n",
      "24             US\n",
      "25             Rs\n",
      "26          India\n",
      "27          India\n",
      "28    Uttarakhand\n",
      "29    Uttarakhand\n",
      "30          India\n",
      "31          India\n",
      "32          India\n",
      "33          India\n",
      "34         Turkey\n",
      "35         Turkey\n",
      "36         Turkey\n",
      "37      Indonesia\n",
      "38      Indonesia\n",
      "39          India\n",
      "Name: location, dtype: object\n",
      "40          India\n",
      "41          India\n",
      "42         Munnar\n",
      "43             US\n",
      "44    Uttarakhand\n",
      "45          India\n",
      "46          India\n",
      "47          India\n",
      "48    Uttarakhand\n",
      "49    Uttarakhand\n",
      "50          India\n",
      "51          India\n",
      "52          India\n",
      "53          India\n",
      "54          India\n",
      "55          India\n",
      "56          India\n",
      "57          India\n",
      "58          India\n",
      "59          India\n",
      "Name: location, dtype: object\n",
      "60                 India\n",
      "61                 India\n",
      "62                 Earth\n",
      "63                 Earth\n",
      "64                 Earth\n",
      "65                 Earth\n",
      "66    North Indian Ocean\n",
      "67    North Indian Ocean\n",
      "68                 India\n",
      "69                 India\n",
      "70                 India\n",
      "71                 India\n",
      "72                Odisha\n",
      "73                Odisha\n",
      "74                Odisha\n",
      "75                Odisha\n",
      "76                 India\n",
      "77                 India\n",
      "78                 India\n",
      "79                 India\n",
      "Name: location, dtype: object\n",
      "80           Uttarakhand\n",
      "81           Uttarakhand\n",
      "82           Uttarakhand\n",
      "83       Sangli Kolhapur\n",
      "84       Sangli Kolhapur\n",
      "85                Kerala\n",
      "86         Visakhapatnam\n",
      "87                 India\n",
      "88                 India\n",
      "89                 India\n",
      "90                 India\n",
      "91                 India\n",
      "92                 India\n",
      "93                 India\n",
      "94                 India\n",
      "95                 Patna\n",
      "96                 Patna\n",
      "97    West Bengal-Odisha\n",
      "98                 India\n",
      "99                 India\n",
      "Name: location, dtype: object\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:86: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0                India\n",
      "1                India\n",
      "2                India\n",
      "3                India\n",
      "4                India\n",
      "5                India\n",
      "6                India\n",
      "7                India\n",
      "8                India\n",
      "9                India\n",
      "10               India\n",
      "11              Kerala\n",
      "12              Kerala\n",
      "13              Kerala\n",
      "14              Kerala\n",
      "15              Kerala\n",
      "16              Kerala\n",
      "17    Biological Risks\n",
      "18    Biological Risks\n",
      "19         Kerala Post\n",
      "Name: disaster, dtype: object\n",
      "20                        Karnataka's\n",
      "21                        Karnataka's\n",
      "22    the Deadliest Natural Disasters\n",
      "23    the Deadliest Natural Disasters\n",
      "24    the Deadliest Natural Disasters\n",
      "25                     Madhya Pradesh\n",
      "26                     Madhya Pradesh\n",
      "27                   Mountain Warming\n",
      "28                   Mountain Warming\n",
      "29                   Mountain Warming\n",
      "30                   Mountain Warming\n",
      "31                   Mountain Warming\n",
      "32                   Mountain Warming\n",
      "33                   Mountain Warming\n",
      "34                   Mountain Warming\n",
      "35                         Land Prone\n",
      "36                         Land Prone\n",
      "37                         Land Prone\n",
      "38                         Land Prone\n",
      "39                         Land Prone\n",
      "Name: disaster, dtype: object\n",
      "40                         Land Prone\n",
      "41                         Land Prone\n",
      "42                         Land Prone\n",
      "43    the Deadliest Natural Disasters\n",
      "44    the Deadliest Natural Disasters\n",
      "45       Are Major Natural Calamities\n",
      "46                          Air India\n",
      "47        Deadliest Natural Disasters\n",
      "48        Deadliest Natural Disasters\n",
      "49        Deadliest Natural Disasters\n",
      "50        Deadliest Natural Disasters\n",
      "51                          Migration\n",
      "52                          Migration\n",
      "53                          Migration\n",
      "54                          Migration\n",
      "55                          Migration\n",
      "56                              Vizag\n",
      "57                              Vizag\n",
      "58                              Vizag\n",
      "59                              Vizag\n",
      "Name: disaster, dtype: object\n",
      "60                         UN\n",
      "61                         UN\n",
      "62                         UN\n",
      "63                         UN\n",
      "64                         UN\n",
      "65                     Kerala\n",
      "66                     Kerala\n",
      "67                       CNBC\n",
      "68                       CNBC\n",
      "69                       CNBC\n",
      "70                   COVID‐19\n",
      "71                   COVID‐19\n",
      "72                   COVID‐19\n",
      "73                   COVID‐19\n",
      "74                      World\n",
      "75                      World\n",
      "76                      World\n",
      "77            Worst Pandemics\n",
      "78            Worst Pandemics\n",
      "79    Chemical Accident Rules\n",
      "Name: disaster, dtype: object\n",
      "80    Chemical Accident Rules\n",
      "81    Chemical Accident Rules\n",
      "82                       Gaja\n",
      "83                Maharashtra\n",
      "84                Maharashtra\n",
      "85                Maharashtra\n",
      "86                      Vizag\n",
      "87              Western Ghats\n",
      "88              Western Ghats\n",
      "89                Maharashtra\n",
      "90                   Himalaya\n",
      "91                   Himalaya\n",
      "92                   Himalaya\n",
      "93                   Himalaya\n",
      "94                   Himalaya\n",
      "95                   Himalaya\n",
      "96                   Himalaya\n",
      "97                   Himalaya\n",
      "98                   Himalaya\n",
      "99                   Himalaya\n",
      "Name: disaster, dtype: object\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:116: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0                   2020\n",
      "1             two-decade\n",
      "2     Last Three Decades\n",
      "3     Last Three Decades\n",
      "4     Last Three Decades\n",
      "5     Last Three Decades\n",
      "6       1st half of 2020\n",
      "7                   2019\n",
      "8           2019 - World\n",
      "9           2019 - World\n",
      "10          2019 - World\n",
      "11          2019 - World\n",
      "12          2019 - World\n",
      "13          2019 - World\n",
      "14          2019 - World\n",
      "15             this year\n",
      "16      Financial Year '\n",
      "17      Financial Year '\n",
      "18      Financial Year '\n",
      "19      Financial Year '\n",
      "Name: Date/Duration, dtype: object\n",
      "20                 2\n",
      "21                 2\n",
      "22              2018\n",
      "23              2018\n",
      "24              2018\n",
      "25              2018\n",
      "26              2018\n",
      "27              2018\n",
      "28              2018\n",
      "29              2018\n",
      "30              2018\n",
      "31    the worst year\n",
      "32    the worst year\n",
      "33             22165\n",
      "34             22165\n",
      "35          2004-16’\n",
      "36              2018\n",
      "37              2018\n",
      "38              2018\n",
      "39              2018\n",
      "Name: Date/Duration, dtype: object\n",
      "40               2018\n",
      "41               2020\n",
      "42               2020\n",
      "43               2019\n",
      "44               2013\n",
      "45    Year-Ender 2019\n",
      "46    Year-Ender 2019\n",
      "47               2019\n",
      "48               2019\n",
      "49           27 years\n",
      "50           27 years\n",
      "51           27 years\n",
      "52           27 years\n",
      "53               2019\n",
      "54               2019\n",
      "55               2019\n",
      "56               2019\n",
      "57               2019\n",
      "58               2019\n",
      "59               2019\n",
      "Name: Date/Duration, dtype: object\n",
      "60              last 20 years\n",
      "61              last 20 years\n",
      "62                       2019\n",
      "63                       2019\n",
      "64                       2019\n",
      "65                       2019\n",
      "66                       2019\n",
      "67                       2019\n",
      "68                  Four days\n",
      "69                       2001\n",
      "70                       2001\n",
      "71                       2001\n",
      "72    20 years before Cyclone\n",
      "73    20 years before Cyclone\n",
      "74    20 years before Cyclone\n",
      "75    20 years before Cyclone\n",
      "76    20 years before Cyclone\n",
      "77               1720 to 2020\n",
      "78                       2017\n",
      "79                       2017\n",
      "Name: Date/Duration, dtype: object\n",
      "80                 2017\n",
      "81                 2017\n",
      "82                 2017\n",
      "83                 2017\n",
      "84    the past 50 years\n",
      "85            a century\n",
      "86            a century\n",
      "87            a century\n",
      "88            a century\n",
      "89            a century\n",
      "90            a century\n",
      "91        a lakh a year\n",
      "92        a lakh a year\n",
      "93                 2019\n",
      "94                 2020\n",
      "95                 2020\n",
      "96                 2020\n",
      "97                 2020\n",
      "98         1947 to 2019\n",
      "99      every 100 years\n",
      "Name: Date/Duration, dtype: object\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#intensity \n",
    "import numpy as np # \n",
    "import pandas as pd # \n",
    "\n",
    "import os\n",
    "import pandas\n",
    "df_review = pandas.read_excel('output.xlsx')\n",
    "#df_review['Descript'][0]\n",
    "df_review['intensity']=''\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "\n",
    "sentences=list(df_review['Descript'])\n",
    "analyzer = SentimentIntensityAnalyzer()\n",
    "count=0\n",
    "for sentence in sentences:\n",
    "    count+=1\n",
    "    vs = analyzer.polarity_scores(sentence)\n",
    "    t=vs['compound']\n",
    "    #print(t)\n",
    "    #print(vs,count,t)\n",
    "    if vs['compound']>= 0.05:\n",
    "        df_review['intensity'][count-1]=\"Low Intensity\"\n",
    "    elif vs['compound']>-0.05 and vs['compound']<0.05:\n",
    "        df_review['intensity'][count-1]=\"Medium Intensity\"\n",
    "    elif vs['compound']<= -0.05:\n",
    "        df_review['intensity'][count-1]=\"High Intensity\"\n",
    "df_review['intensity']        \n",
    "        \n",
    "df_review.to_excel('intensityoutput.xlsx')   \n",
    "\n",
    "#location\n",
    "import pandas as pd\n",
    "import spacy\n",
    "import en_core_web_sm\n",
    "df_review = pd.read_excel('intensityoutput.xlsx')\n",
    "df_review.drop(['Link'], axis = 1)\n",
    "df_review['location']=''\n",
    "#print(df_review)\n",
    "for i in range(len(df_review['Descript'])):\n",
    "    \n",
    "    sentence=df_review['Title'][i]\n",
    "    spacy_model = en_core_web_sm.load()\n",
    "    entity_doc = spacy_model(sentence)\n",
    "    entity_doc.ents\n",
    "    t=(([(entity.text, entity .label_)for entity in entity_doc.ents]))\n",
    "    for j in range(len(t)):\n",
    "        #print(i,t,t[j][1])\n",
    "    \n",
    "        if (t[j][1]=='GPE' or t[j][1]=='LOC'):\n",
    "            k=t[j][0]\n",
    "        else:\n",
    "            continue      \n",
    "                        \n",
    "                     \n",
    "    df_review['location'][i]=k\n",
    "print(df_review['location'][0:20])\n",
    "print(df_review['location'][20:40])\n",
    "print(df_review['location'][40:60])\n",
    "print(df_review['location'][60:80])\n",
    "print(df_review['location'][80:100])\n",
    "df_review.to_excel(\"test.xlsx\")\n",
    "#disasters\n",
    "import pandas as pd\n",
    "import spacy\n",
    "import en_core_web_sm\n",
    "df_review = pd.read_excel('intensityoutput.xlsx')\n",
    "df_review.drop(['Link'], axis = 1)\n",
    "df_review['disaster']=''\n",
    "for i in range(len(df_review['Descript'])):\n",
    "    \n",
    "    sentence=df_review['Title'][i]\n",
    "    spacy_model = en_core_web_sm.load()\n",
    "    entity_doc = spacy_model(sentence)\n",
    "    entity_doc.ents\n",
    "    t=(([(entity.text, entity .label_)for entity in entity_doc.ents]))\n",
    "    for j in range(len(t)):\n",
    "        #print(i,t,t[j][1])\n",
    "    \n",
    "        if (t[j][1]=='ORG'):\n",
    "            k=t[j][0]\n",
    "        else:\n",
    "            continue      \n",
    "                        \n",
    "                     \n",
    "    df_review['disaster'][i]=k\n",
    "#column for various disasters\n",
    "print(df_review['disaster'][0:20])\n",
    "print(df_review['disaster'][20:40])\n",
    "print(df_review['disaster'][40:60])\n",
    "print(df_review['disaster'][60:80])\n",
    "print(df_review['disaster'][80:100])\n",
    "df_review.to_excel(\"test.xlsx\")\n",
    "#Date/duration\n",
    "import pandas as pd\n",
    "import spacy\n",
    "import en_core_web_sm\n",
    "df_review = pd.read_excel('intensityoutput.xlsx')\n",
    "df_review.drop(['Link'], axis = 1)\n",
    "df_review['Date/Duration']=''\n",
    "for i in range(len(df_review['Descript'])):\n",
    "    \n",
    "    sentence=df_review['Title'][i]\n",
    "    spacy_model = en_core_web_sm.load()\n",
    "    entity_doc = spacy_model(sentence)\n",
    "    entity_doc.ents\n",
    "    t=(([(entity.text, entity .label_)for entity in entity_doc.ents]))\n",
    "    for j in range(len(t)):\n",
    "        #print(j,t,t[j][1])\n",
    "    \n",
    "        if (t[j][1]=='DATE'):\n",
    "            k=t[j][0]\n",
    "        else:\n",
    "            continue      \n",
    "                        \n",
    "                     \n",
    "    df_review['Date/Duration'][i]=k\n",
    "#date/duration column    \n",
    "print(df_review['Date/Duration'][0:20])\n",
    "print(df_review['Date/Duration'][20:40])\n",
    "print(df_review['Date/Duration'][40:60])\n",
    "print(df_review['Date/Duration'][60:80])\n",
    "print(df_review['Date/Duration'][80:100])\n",
    "df_review.to_excel(\"test.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>5 months ago</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>4 months ago</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>4 months ago</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>3 months ago</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>4 months ago</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>95</td>\n",
       "      <td>12 months ago</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>96</td>\n",
       "      <td>24 months ago</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>97</td>\n",
       "      <td>12 months ago</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>98</td>\n",
       "      <td>21 months ago</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>99</td>\n",
       "      <td>14 months ago</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Unnamed: 0           Time\n",
       "0            0  5 months ago \n",
       "1            1  4 months ago \n",
       "2            2  4 months ago \n",
       "3            3  3 months ago \n",
       "4            4  4 months ago \n",
       "..         ...            ...\n",
       "95          95  12 months ago\n",
       "96          96  24 months ago\n",
       "97          97  12 months ago\n",
       "98          98  21 months ago\n",
       "99          99  14 months ago\n",
       "\n",
       "[100 rows x 2 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np # \n",
    "import pandas as pd # \n",
    "\n",
    "import os\n",
    "import pandas\n",
    "df_review = pd.read_excel('output.xlsx')\n",
    "df_review.pop('Title')\n",
    "df_review.pop('Descript')\n",
    "df_review.pop('Link')\n",
    "df_review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:36: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "C:\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:32: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "C:\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:34: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "C:\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:70: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "C:\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:101: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'result' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-38-5386f245c4ed>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m    110\u001b[0m \u001b[0mdf_review\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf_review\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    111\u001b[0m \u001b[0mdf_review\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_excel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"result.xlsx\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 112\u001b[1;33m \u001b[0mresult\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'result' is not defined"
     ]
    }
   ],
   "source": [
    "import numpy as np # \n",
    "import pandas as pd # \n",
    "\n",
    "import os\n",
    "import pandas\n",
    "df_review = pd.read_excel('output.xlsx')\n",
    "df_review.pop('Title')\n",
    "df_review.pop('Descript')\n",
    "df_review.pop('Link')\n",
    "df_review\n",
    "#intensity \n",
    "import numpy as np # \n",
    "import pandas as pd # \n",
    "\n",
    "import os\n",
    "import pandas\n",
    "df_review = pandas.read_excel('output.xlsx')\n",
    "#df_review['Descript'][0]\n",
    "df_review['intensity']=''\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "\n",
    "sentences=list(df_review['Descript'])\n",
    "analyzer = SentimentIntensityAnalyzer()\n",
    "count=0\n",
    "for sentence in sentences:\n",
    "    count+=1\n",
    "    vs = analyzer.polarity_scores(sentence)\n",
    "    t=vs['compound']\n",
    "    #print(t)\n",
    "    #print(vs,count,t)\n",
    "    if vs['compound']>= 0.05:\n",
    "        df_review['intensity'][count-1]=\"Low Intensity\"\n",
    "    elif vs['compound']>-0.05 and vs['compound']<0.05:\n",
    "        df_review['intensity'][count-1]=\"Medium Intensity\"\n",
    "    elif vs['compound']<= -0.05:\n",
    "        df_review['intensity'][count-1]=\"High Intensity\"\n",
    "#df_review['intensity']        \n",
    "        \n",
    "  \n",
    "\n",
    "#print(df_review['location'][0:20])\n",
    "#print(df_review['location'][20:40])\n",
    "#print(df_review['location'][40:60])\n",
    "#print(df_review['location'][60:80])\n",
    "#print(df_review['location'][80:100])\n",
    "#df_review.to_excel(\"test.xlsx\")\n",
    "#disasters\n",
    "import pandas as pd\n",
    "import spacy\n",
    "import en_core_web_sm\n",
    "df_review = pd.read_excel('intensityoutput.xlsx')\n",
    "df_review.drop(['Link'], axis = 1)\n",
    "df_review['disaster']=''\n",
    "for i in range(len(df_review['Descript'])):\n",
    "    \n",
    "    sentence=df_review['Title'][i]\n",
    "    spacy_model = en_core_web_sm.load()\n",
    "    entity_doc = spacy_model(sentence)\n",
    "    entity_doc.ents\n",
    "    t=(([(entity.text, entity .label_)for entity in entity_doc.ents]))\n",
    "    for j in range(len(t)):\n",
    "        #print(i,t,t[j][1])\n",
    "    \n",
    "        if (t[j][1]=='ORG'):\n",
    "            k=t[j][0]\n",
    "        else:\n",
    "            continue      \n",
    "                        \n",
    "                     \n",
    "    df_review['disaster'][i]=k\n",
    "df_review['disaster']    \n",
    "#print(df_review['disaster'][0:20])\n",
    "#print(df_review['disaster'][20:40])\n",
    "#print(df_review['disaster'][40:60])\n",
    "#print(df_review['disaster'][60:80])\n",
    "#print(df_review['disaster'][80:100])\n",
    "\n",
    "#Date/duration\n",
    "import pandas as pd\n",
    "import spacy\n",
    "import en_core_web_sm\n",
    "df_review = pd.read_excel('intensityoutput.xlsx')\n",
    "df_review.drop(['Link'], axis = 1)\n",
    "df_review['Date/Duration']=''\n",
    "for i in range(len(df_review['Descript'])):\n",
    "    \n",
    "    sentence=df_review['Title'][i]\n",
    "    spacy_model = en_core_web_sm.load()\n",
    "    entity_doc = spacy_model(sentence)\n",
    "    entity_doc.ents\n",
    "    t=(([(entity.text, entity .label_)for entity in entity_doc.ents]))\n",
    "    for j in range(len(t)):\n",
    "        #print(j,t,t[j][1])\n",
    "    \n",
    "        if (t[j][1]=='DATE'):\n",
    "            k=t[j][0]\n",
    "        else:\n",
    "            continue      \n",
    "                        \n",
    "                     \n",
    "    df_review['Date/Duration'][i]=k\n",
    "#print(df_review['Date/Duration'][0:20])\n",
    "#print(df_review['Date/Duration'][20:40])\n",
    "#print(df_review['Date/Duration'][40:60])\n",
    "#print(df_review['Date/Duration'][60:80])\n",
    "#print(df_review['Date/Duration'][80:100])\n",
    "df_review.pop(\"Link\")\n",
    "df_review.pop(\"Title\")\n",
    "df_review.pop(\"Descript\")\n",
    "df_review.drop(df_review.columns[[0,1,]], axis=1, inplace=True)\n",
    "df_review.to_excel(\"result.xlsx\")\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:23: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Time</th>\n",
       "      <th>Title</th>\n",
       "      <th>Descript</th>\n",
       "      <th>Link</th>\n",
       "      <th>disaster</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>5 months ago</td>\n",
       "      <td>Disasters that struck India in 2020</td>\n",
       "      <td>India amidst the raging pandemic survived cyc...</td>\n",
       "      <td>https://timesofindia.indiatimes.com/india/disa...</td>\n",
       "      <td>every 100 years</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>4 months ago</td>\n",
       "      <td>300 disasters 80000 deaths 100 crore affected:...</td>\n",
       "      <td>Both nations accounted for over 280 crore dis...</td>\n",
       "      <td>https://www.indiatoday.in/diu/story/300-disast...</td>\n",
       "      <td>every 100 years</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>4 months ago</td>\n",
       "      <td>A Look At Natural Disasters Uttarakhand Faced ...</td>\n",
       "      <td>Take a look at the major natural disasters Ut...</td>\n",
       "      <td>https://www.outlookindia.com/website/story/ind...</td>\n",
       "      <td>every 100 years</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>3 months ago</td>\n",
       "      <td>Uttarakhand dam disaster: What caused India's ...</td>\n",
       "      <td>... analysed the cause of the flood that has ...</td>\n",
       "      <td>https://news.sky.com/story/uttarakhand-dam-dis...</td>\n",
       "      <td>every 100 years</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>4 months ago</td>\n",
       "      <td>Global warming and vanishing glaciers: Is risi...</td>\n",
       "      <td>The disaster in Uttarakhand has once again tu...</td>\n",
       "      <td>https://www.indiatoday.in/diu/story/global-war...</td>\n",
       "      <td>every 100 years</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>95</td>\n",
       "      <td>12 months ago</td>\n",
       "      <td>When Karachi-like plane crash happened in Patn...</td>\n",
       "      <td>� One of them received no injuries barring a f...</td>\n",
       "      <td>https://www.indiatoday.in/india/story/karachi-...</td>\n",
       "      <td>Himalaya</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>96</td>\n",
       "      <td>24 months ago</td>\n",
       "      <td>9 man-made disasters that had a big impact on ...</td>\n",
       "      <td>� You may hear about natural disasters often b...</td>\n",
       "      <td>https://www.businessinsider.com/the-biggest-ma...</td>\n",
       "      <td>Himalaya</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>97</td>\n",
       "      <td>12 months ago</td>\n",
       "      <td>Cyclone Amphan tears through West Bengal-Odish...</td>\n",
       "      <td>� A tidal surge of up to five metres occurred ...</td>\n",
       "      <td>https://www.indiatoday.in/india/story/cyclone-...</td>\n",
       "      <td>Himalaya</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>98</td>\n",
       "      <td>21 months ago</td>\n",
       "      <td>Independence Day: 73 events that define India’...</td>\n",
       "      <td>� In its 72 years of independence India has se...</td>\n",
       "      <td>https://indianexpress.com/article/india/indepe...</td>\n",
       "      <td>Himalaya</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>99</td>\n",
       "      <td>14 months ago</td>\n",
       "      <td>From 1720 to 2020: How pandemics have threaten...</td>\n",
       "      <td>� Radio: Ishq FM. Education: India Today Educa...</td>\n",
       "      <td>https://www.indiatoday.in/coronavirus-outbreak...</td>\n",
       "      <td>Himalaya</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Unnamed: 0           Time  \\\n",
       "0            0  5 months ago    \n",
       "1            1  4 months ago    \n",
       "2            2  4 months ago    \n",
       "3            3  3 months ago    \n",
       "4            4  4 months ago    \n",
       "..         ...            ...   \n",
       "95          95  12 months ago   \n",
       "96          96  24 months ago   \n",
       "97          97  12 months ago   \n",
       "98          98  21 months ago   \n",
       "99          99  14 months ago   \n",
       "\n",
       "                                                Title  \\\n",
       "0                 Disasters that struck India in 2020   \n",
       "1   300 disasters 80000 deaths 100 crore affected:...   \n",
       "2   A Look At Natural Disasters Uttarakhand Faced ...   \n",
       "3   Uttarakhand dam disaster: What caused India's ...   \n",
       "4   Global warming and vanishing glaciers: Is risi...   \n",
       "..                                                ...   \n",
       "95  When Karachi-like plane crash happened in Patn...   \n",
       "96  9 man-made disasters that had a big impact on ...   \n",
       "97  Cyclone Amphan tears through West Bengal-Odish...   \n",
       "98  Independence Day: 73 events that define India’...   \n",
       "99  From 1720 to 2020: How pandemics have threaten...   \n",
       "\n",
       "                                             Descript  \\\n",
       "0    India amidst the raging pandemic survived cyc...   \n",
       "1    Both nations accounted for over 280 crore dis...   \n",
       "2    Take a look at the major natural disasters Ut...   \n",
       "3    ... analysed the cause of the flood that has ...   \n",
       "4    The disaster in Uttarakhand has once again tu...   \n",
       "..                                                ...   \n",
       "95  � One of them received no injuries barring a f...   \n",
       "96  � You may hear about natural disasters often b...   \n",
       "97  � A tidal surge of up to five metres occurred ...   \n",
       "98  � In its 72 years of independence India has se...   \n",
       "99  � Radio: Ishq FM. Education: India Today Educa...   \n",
       "\n",
       "                                                 Link         disaster  \n",
       "0   https://timesofindia.indiatimes.com/india/disa...  every 100 years  \n",
       "1   https://www.indiatoday.in/diu/story/300-disast...  every 100 years  \n",
       "2   https://www.outlookindia.com/website/story/ind...  every 100 years  \n",
       "3   https://news.sky.com/story/uttarakhand-dam-dis...  every 100 years  \n",
       "4   https://www.indiatoday.in/diu/story/global-war...  every 100 years  \n",
       "..                                                ...              ...  \n",
       "95  https://www.indiatoday.in/india/story/karachi-...         Himalaya  \n",
       "96  https://www.businessinsider.com/the-biggest-ma...         Himalaya  \n",
       "97  https://www.indiatoday.in/india/story/cyclone-...         Himalaya  \n",
       "98  https://indianexpress.com/article/india/indepe...         Himalaya  \n",
       "99  https://www.indiatoday.in/coronavirus-outbreak...         Himalaya  \n",
       "\n",
       "[100 rows x 6 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#location\n",
    "import pandas as pd\n",
    "import spacy\n",
    "import en_core_web_sm\n",
    "df_review = pd.read_excel('output.xlsx')\n",
    "df_review['disaster']=''\n",
    "for i in range(len(df_review['Descript'])):\n",
    "    \n",
    "    sentence=df_review['Title'][i]\n",
    "    spacy_model = en_core_web_sm.load()\n",
    "    entity_doc = spacy_model(sentence)\n",
    "    entity_doc.ents\n",
    "    t=(([(entity.text, entity .label_)for entity in entity_doc.ents]))\n",
    "    for j in range(len(t)):\n",
    "        #print(i,t,t[j][1])\n",
    "    \n",
    "        if (t[j][1]=='ORG'):\n",
    "            k=t[j][0]\n",
    "        else:\n",
    "            continue      \n",
    "                        \n",
    "                     \n",
    "    df_review['disaster'][i]=k\n",
    "df_review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:26: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "C:\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:44: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'intensity'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32mC:\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   2896\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2897\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2898\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'intensity'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-a2b258eb7073>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     47\u001b[0m \u001b[0mdf_review\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Link\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     48\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_excel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'result.xlsx'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 49\u001b[1;33m \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"intensity\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdf_review\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"intensity\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     50\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Duration'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdf_review\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"Duration\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     51\u001b[0m \u001b[0mdf_review\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_excel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"result.xlsx\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   2993\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2994\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2995\u001b[1;33m             \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2996\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2997\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   2897\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2898\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2899\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_cast_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2900\u001b[0m         \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtolerance\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtolerance\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2901\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mindexer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mindexer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'intensity'"
     ]
    }
   ],
   "source": [
    "\n",
    "#location\n",
    "import pandas as pd\n",
    "import spacy\n",
    "import en_core_web_sm\n",
    "df_review = pd.read_excel('output.xlsx')\n",
    "df_review.drop(['Link'], axis = 1)\n",
    "df_review['location']=''\n",
    "#print(df_review)\n",
    "for i in range(len(df_review['Descript'])):\n",
    "    \n",
    "    sentence=df_review['Title'][i]\n",
    "    spacy_model = en_core_web_sm.load()\n",
    "    entity_doc = spacy_model(sentence)\n",
    "    entity_doc.ents\n",
    "    t=(([(entity.text, entity .label_)for entity in entity_doc.ents]))\n",
    "    for j in range(len(t)):\n",
    "        #print(i,t,t[j][1])\n",
    "    \n",
    "        if (t[j][1]=='GPE' or t[j][1]=='LOC'):\n",
    "            k=t[j][0]\n",
    "        else:\n",
    "            continue      \n",
    "                        \n",
    "                     \n",
    "    df_review['location'][i]=k\n",
    "df_review['disaster']=''\n",
    "for i in range(len(df_review['Descript'])):\n",
    "    \n",
    "    sentence=df_review['Title'][i]\n",
    "    spacy_model = en_core_web_sm.load()\n",
    "    entity_doc = spacy_model(sentence)\n",
    "    entity_doc.ents\n",
    "    t=(([(entity.text, entity .label_)for entity in entity_doc.ents]))\n",
    "    for j in range(len(t)):\n",
    "        #print(i,t,t[j][1])\n",
    "    \n",
    "        if (t[j][1]=='ORG'):\n",
    "            k=t[j][0]\n",
    "        else:\n",
    "            continue      \n",
    "                        \n",
    "                     \n",
    "    df_review['disaster'][i]=k    \n",
    "df_review.pop(\"Descript\")\n",
    "df_review.pop(\"Title\")\n",
    "df_review.pop(\"Link\")\n",
    "df=pd.read_excel('result.xlsx')\n",
    "df[\"intensity\"]=df_review[\"intensity\"]\n",
    "df['Duration']=df_review[\"Duration\"]\n",
    "df_review.to_excel(\"result.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#location\n",
    "import pandas as pd\n",
    "import spacy\n",
    "import en_core_web_sm\n",
    "df_review = pd.read_excel('output.xlsx')\n",
    "df_review.drop(['Link'], axis = 1)\n",
    "df_review['location']=''\n",
    "#print(df_review)\n",
    "for i in range(len(df_review['Descript'])):\n",
    "    \n",
    "    sentence=df_review['Title'][i]\n",
    "    spacy_model = en_core_web_sm.load()\n",
    "    entity_doc = spacy_model(sentence)\n",
    "    entity_doc.ents\n",
    "    t=(([(entity.text, entity .label_)for entity in entity_doc.ents]))\n",
    "    for j in range(len(t)):\n",
    "        #print(i,t,t[j][1])\n",
    "    \n",
    "        if (t[j][1]=='GPE' or t[j][1]=='LOC'):\n",
    "            k=t[j][0]\n",
    "        else:\n",
    "            continue      \n",
    "                        \n",
    "                     \n",
    "    df_review['location'][i]=k\n",
    "df_review['disaster']=''\n",
    "for i in range(len(df_review['Descript'])):\n",
    "    \n",
    "    sentence=df_review['Title'][i]\n",
    "    spacy_model = en_core_web_sm.load()\n",
    "    entity_doc = spacy_model(sentence)\n",
    "    entity_doc.ents\n",
    "    t=(([(entity.text, entity .label_)for entity in entity_doc.ents]))\n",
    "    for j in range(len(t)):\n",
    "        #print(i,t,t[j][1])\n",
    "    \n",
    "        if (t[j][1]=='ORG'):\n",
    "            k=t[j][0]\n",
    "        else:\n",
    "            continue      \n",
    "                        \n",
    "                     \n",
    "    df_review['disaster'][i]=k    \n",
    "df_review.pop(\"Descript\")\n",
    "df_review.pop(\"Title\")\n",
    "df_review.pop(\"Link\")\n",
    "df=pd.read_excel('result.xlsx')\n",
    "df[\"intensity\"]=df_review[\"intensity\"]\n",
    "df['Duration']=df_review[\"Duration\"]\n",
    "df_review.to_excel(\"result.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "t=pd.read_excel(\"result.xlsx\")\n",
    "t.drop(df.columns[[0, 1]], axis = 1, inplace = True)\n",
    "t.to_excel(\"excelresult.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
